


import numpy as np
import pandas as pd
from transformers import pipeline
import math
from nltk.tokenize import word_tokenize
from tqdm import tqdm


rows = 20
chunk = 100
chunk_pipeline = 10


sentiment_pipeline = pipeline("text-classification", model="nlptown/bert-base-multilingual-uncased-sentiment")


def reset_file(df):
    pd.DataFrame([], columns=list(df.columns) + ['label', 'score']).to_csv('dados/reviewsTrainTorontoSentiment.csv', mode='w', header=True, index=False)

def proccess(df):
    results = []
    begining_index = 0
    for index, row in tqdm(df.iterrows(), total=len(df)):
        obj = sentiment_pipeline(row['text'][0:512])[0]
        obj['label'] = int(obj['label'].split(' ')[0])
        results.append(obj)
    
        if(((index+1) % 10 == 0 or (index-1) == len(df)) and index != 0):
            save_df = pd.concat([df.iloc[begining_index:index+1], pd.DataFrame.from_dict(results)], axis=1)
            results = []
            begining_index = index+1
            save_df.to_csv('dados/reviewsTrainTorontoSentiment.csv', mode='a', header=False, index=False)


first = True
for df in pd.read_csv('dados/reviewsTrainToronto.csv', chunksize=chunk):
    if first:
        reset_file(df)
        first = False
    proccess(df)


df = pd.read_csv('dados/reviewsTrainToronto.csv', nrows=10)
df


import nltk
nltk.download('punkt_tab')








pd.concat([df.iloc[begining_index:index+1], pd.DataFrame.from_dict(results)], axis=1)


pd.DataFrame(row).transpose()


result_df


df['text'][0]


sentiment_pipeline(df['text'][0])



