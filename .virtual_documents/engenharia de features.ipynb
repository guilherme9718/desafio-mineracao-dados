


import numpy as np
import pandas as pd
import ast


def literal_eval(x):
    if pd.isna(x):
        return dict()
    raw_dict = ast.literal_eval(x)
    for key in raw_dict:
        raw_dict[key] = ast.literal_eval(raw_dict[key])
    return raw_dict
        
def proccess_df(df):
    df['loc'] = df['loc'].apply(lambda x: ast.literal_eval(x))
    df['attributes'] = df['attributes'].apply(literal_eval)
    df['hours'] = df['hours'].apply(lambda x: ast.literal_eval(x) if not pd.isna(x) else dict())


df = pd.read_csv('dados/X_trainToronto.csv').set_index('business_id')
proccess_df(df)
df








df_reg = df.copy()
df_reg = df_reg[['latitude', 'longitude', 'attributes', 'categories', 'hours', 'destaque']].reset_index()
df_reg





from collections import defaultdict

unique_attributes = defaultdict(set)
two_layer_attributtes = defaultdict(set)
attributes = df['attributes']
for item_dict in attributes:
    for key in item_dict:
        if type(item_dict[key]) is dict:
            for key2 in item_dict[key]:
                two_layer_attributtes[(key, key2)].add(item_dict[key][key2])
        else:
            unique_attributes[key].add(item_dict[key])

for attr1, attr2 in two_layer_attributtes:
    if attr1 in unique_attributes:
        unique_attributes.pop(attr1, None)

def dummy_attr(row):
    atributes = {}
    obj = row['attributes']
    if row['attributes'] == None:
        obj = dict()
    for key in unique_attributes:
        atributes[key] = None
        if key in obj:
            atributes[key] = obj[key]
            
    for attr1, attr2 in two_layer_attributtes:
        key = f'{attr1}.{attr2}'
        atributes[key] = None
        if attr1 in obj and type(obj[attr1]) is dict and attr2 in obj[attr1]:
            atributes[key] = obj[attr1][attr2]
    return atributes

df_attr = pd.DataFrame.from_dict(list(df_reg.apply(dummy_attr, axis=1)))
df_almost_dummie = pd.concat([df_reg, df_attr], axis=1)

df_dummies = pd.get_dummies(df_almost_dummie[df_attr.columns].astype(str))
columns_to_drop = [x for x in list(df_dummies.columns) if ('_nan' in x or '_None' in x or '_none' in x)]
df_dummies = df_dummies.drop(columns_to_drop, axis=1)

df_reg = pd.concat([df_reg, df_dummies], axis=1)
df_reg


all_categories = defaultdict(int)
for c_list in df_reg.categories.str.split(','):
    for c in c_list:
        all_categories[c.strip().lower()] = all_categories[c.strip().lower()] + 1

best_categories = pd.Series(all_categories)
best_categories = best_categories[best_categories > 50]
others_categories = set(all_categories.keys()).difference(set(best_categories.index))
best_categories


from sklearn.preprocessing import MultiLabelBinarizer
df_reg['categories'] = df_reg.categories.astype(str)
categories = df_reg.categories.str.split(',').apply(lambda x: [s.strip().lower() for s in x])

mlb = MultiLabelBinarizer()
df_cat_dummies = pd.DataFrame(mlb.fit_transform(categories),columns=mlb.classes_, index=df_reg.index)
df_cat_dummies['others_categories'] = df_cat_dummies.apply(lambda x: x[list(others_categories)].sum(), axis=1)
df_cat_dummies = df_cat_dummies.drop(list(others_categories), axis=1)
df_reg = pd.concat([df_reg, df_cat_dummies], axis=1)


from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def measure(y_test, y_pred):
    # Calculate accuracy
    accuracy = accuracy_score(y_test, y_pred)
    print("Accuracy:", accuracy)
    
    # Calculate precision
    precision = precision_score(y_test, y_pred)
    print("Precision:", precision)
    
    # Calculate recall (sensitivity)
    recall = recall_score(y_test, y_pred)
    print("Recall (Sensitivity):", recall)
    
    # Calculate F1-score
    f1 = f1_score(y_test, y_pred)
    print("F1-Score:", f1)


from sklearn.model_selection import train_test_split
not_regression_columns = ['business_id', 'attributes', 'categories', 'hours', 'destaque', 'latitude', 'longitude']
df_X = df_reg[[x for x in df_reg.columns if x not in not_regression_columns]]
df_y = df_reg['destaque']
X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.25, random_state=892)
display(X_train)
display(y_train)


from sklearn.tree import DecisionTreeClassifier

clf = DecisionTreeClassifier(random_state=1, max_depth=20)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
measure(y_test, y_pred)


from sklearn.feature_selection import chi2

chi2_stats, p_values = chi2(X_train, y_train)

pd.Series(chi2_stats).sort_values()



